\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}The Big Picture: What Happens When You Type a Prompt?}{3}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Tokenization}{3}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}From Token IDs to Vectors}{3}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Vocabulary Space and Canonical Basis}{4}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Embedding as a Linear Map}{4}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6}Geometry of the Embedding Space}{5}{section.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7}A Concrete Toy Example: Small Vocabulary, Small Embedding Dimension}{5}{section.7}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces A tiny vocabulary and an indexing scheme.}}{5}{table.1}\protected@file@percent }
\newlabel{tab:vocab}{{1}{5}{A tiny vocabulary and an indexing scheme}{table.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}One-hot vectors in $\mathbb  {R}^6$}{5}{subsection.7.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2}Choose a small embedding dimension}{6}{subsection.7.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3}Define an explicit embedding matrix}{6}{subsection.7.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces A hand-chosen embedding matrix $E$ (for illustration). In real LLMs, $E$ is learned.}}{6}{table.2}\protected@file@percent }
\newlabel{tab:embeddings}{{2}{6}{A hand-chosen embedding matrix $E$ (for illustration). In real LLMs, $E$ is learned}{table.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.4}Embed a prompt}{6}{subsection.7.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.5}Geometry now encodes similarity}{7}{subsection.7.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.6}A linear-combination step (attention-like behavior)}{7}{subsection.7.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {8}Positional Encoding}{7}{section.8}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {9}Scaled Dot-Product Attention}{8}{section.9}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {10}Attention as a Kernel Operator}{8}{section.10}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {11}High-Dimensional Geometry}{8}{section.11}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {12}Nonlinear Layers}{9}{section.12}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {13}Variational Interpretation}{9}{section.13}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {14}Spectral Structure}{9}{section.14}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {15}Conceptual Synthesis}{9}{section.15}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {16}Exercises}{10}{section.16}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {17}References}{10}{section.17}\protected@file@percent }
\gdef \@abspage@last{10}
